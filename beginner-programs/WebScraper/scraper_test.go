package WebScraper_test

import (
        "context"
        "io"
        "net/http"
        "strings"
        "testing"

        "github.com/golang/mock/gomock"

        "WebScraper"
        mock_webscraper "WebScraper/mocks" // generated by gomock; see go:generate below
)

/*
        NOTE: To (re-)generate mocks run

            go generate ./...

        The directive below tells `go generate` to create the
        mock that these tests rely on.

        //go:generate mockgen -source=scraper.go -destination=mocks/http_client_mock.go -package=mocks WebScraper HTTPClient
*/

// ----------------------------------------------------------------------------
// FetchHTML
// ----------------------------------------------------------------------------

func TestScraper_FetchHTML(t *testing.T) {
        type args struct {
                url        string
                statusCode int
                body       string
                getErr     error
        }
        tests := []struct {
                name      string
                args      args
                wantHTML  string
                wantErr   bool
        }{
                {
                        name: "happy-path",
                        args: args{
                                url:        "http://example.com",
                                statusCode: http.StatusOK,
                                body:       "<html>ok</html>",
                        },
                        wantHTML: "<html>ok</html>",
                },
                {
                        name: "non-200 status code",
                        args: args{
                                url:        "http://example.com/bad",
                                statusCode: http.StatusBadGateway,
                                body:       "bad",
                        },
                        wantErr: true,
                },
        }

        for _, tt := range tests {
                tt := tt // capture range variable
                t.Run(tt.name, func(t *testing.T) {
                        ctrl := gomock.NewController(t)
                        defer ctrl.Finish()

                        mockClient := mock_webscraper.NewMockHTTPClient(ctrl)
                        mockResp := &http.Response{
                                StatusCode: tt.args.statusCode,
                                Body:       io.NopCloser(strings.NewReader(tt.args.body)),
                        }

                        mockClient.
                                EXPECT().
                                Get(tt.args.url).
                                Return(mockResp, tt.args.getErr)

                        sut := WebScraper.NewScraper(mockClient)

                        gotHTML, err := sut.FetchHTML(context.Background(), tt.args.url)
                        if (err != nil) != tt.wantErr {
                                t.Fatalf("FetchHTML() error = %v, wantErr %v", err, tt.wantErr)
                        }
                        if !tt.wantErr && gotHTML != tt.wantHTML {
                                t.Fatalf("FetchHTML() = %q, want %q", gotHTML, tt.wantHTML)
                        }
                })
        }
}

// ----------------------------------------------------------------------------
// ExtractLinks
// ----------------------------------------------------------------------------

func TestScraper_ExtractLinks(t *testing.T) {
        tests := []struct {
                name     string
                html     string
                want     []string
                wantErr  bool
        }{
                {
                        name: "multiple anchors",
                        html: `<a href="a.html">A</a><a href="/b">B</a><a name="skip-me"></a>`,
                        want: []string{"a.html", "/b"},
                },
                {
                        name:    "malformed html",
                        html:    `<a href="x">X`,
                        want:    []string{"x"},
                        wantErr: false, // parser should still succeed
                },
        }

        for _, tt := range tests {
                tt := tt
                t.Run(tt.name, func(t *testing.T) {
                        got, err := WebScraper.ExtractLinks(tt.html)
                        if (err != nil) != tt.wantErr {
                                t.Fatalf("ExtractLinks() error = %v, wantErr %v", err, tt.wantErr)
                        }
                        if len(got) != len(tt.want) {
                                t.Fatalf("ExtractLinks() len = %d, want %d; got=%v", len(got), len(tt.want), got)
                        }
                        for i := range got {
                                if got[i] != tt.want[i] {
                                        t.Fatalf("ExtractLinks()[%d] = %q, want %q", i, got[i], tt.want[i])
                                }
                        }
                })
        }
}

// ----------------------------------------------------------------------------
// ScrapeLinks (end-to-end)
// ----------------------------------------------------------------------------

func TestScraper_ScrapeLinks(t *testing.T) {
        ctrl := gomock.NewController(t)
        defer ctrl.Finish()

        const (
                url  = "http://example.com"
                html = `<html><body>
                            <a href="one.html">One</a>
                            <a href="/two">Two</a>
                        </body></html>`
        )

        mockClient := mock_webscraper.NewMockHTTPClient(ctrl)
        mockResp := &http.Response{
                StatusCode: http.StatusOK,
                Body:       io.NopCloser(strings.NewReader(html)),
        }

        mockClient.
                EXPECT().
                Get(url).
                Return(mockResp, nil)

        sut := WebScraper.NewScraper(mockClient)

        got, err := sut.ScrapeLinks(context.Background(), url)
        if err != nil {
                t.Fatalf("ScrapeLinks() unexpected error: %v", err)
        }

        want := []string{"one.html", "/two"}
        if len(got) != len(want) {
                t.Fatalf("ScrapeLinks() len = %d, want %d; got=%v", len(got), len(want), got)
        }
        for i := range want {
                if got[i] != want[i] {
                        t.Fatalf("ScrapeLinks()[%d] = %q, want %q", i, got[i], want[i])
                }
        }
}
